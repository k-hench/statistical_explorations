---
output:
  html_document:
  theme: yeti
pdf_document: default
editor_options: 
  chunk_output_type: console
---

# Rethinking: Chapter 9

**Markov Chain Monte Carlo**

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment = "#>", 
                      dev = "svg",         # for html rendering
                      # dev = "cairo_pdf", # for pdf rendering
                      fig.asp = .5, 
                      fig.align = "center",
                      message = FALSE,
                      warning = FALSE)

source("bayesian_settings.R")
source("knitr_matrix.R")
```

by [Richard McElreath](https://xcelab.net/rm/statistical-rethinking/), building on the Summaries by [Solomon Kurz](https://bookdown.org/content/4857/) and [Jake Thompson](https://sr2-solutions.wjakethompson.com/linear-models.html).


## The island Kingdom

```{r, fig.asp = .4}
set.seed(42)
n_weeks <- 1e5
positions <-  rep(0, n_weeks)

current <- 10
for( i in seq_along(positions)){
  # record the current position
  positions[i] <- current
  
  # flip the coin to get the proposal
  proposal <- current + sample(c(-1, 1), size = 1)
  # connecting the edges to make the archipelago circular
  if(proposal == 0){proposal <- 10}
  if(proposal == 11){proposal <- 1}
  # decide whether to move
  prob_move <- proposal/current
  current <- ifelse(runif(1) < prob_move, proposal, current)
}

data_markov <- tibble(
  week = seq_along(positions),
  position = positions)

p1 <- data_markov %>% 
  filter(week < 101) %>% 
  ggplot(aes(x = week, y = position)) +
  geom_point(shape = 21, color = clr0dd, fill = fll0)

p2 <- data_markov %>% 
  ggplot(aes(x = position)) +
  geom_histogram(breaks = 0:10, color = clr0dd, fill = fll0) +
  scale_x_continuous(breaks = .5 + 0:9, labels = 1:10) +
  theme(panel.grid.major.x = element_blank())

p1 + p2
```

## Metropolis algotithms

> bivariate distribution “with a strong negative correlation of -0.9”

\begin{align*}
\begin{bmatrix} \text a_1 \\ \text a_2 \end{bmatrix} & \sim \operatorname{MVNormal} \left (\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \mathbf \Sigma \right) \\
\mathbf \Sigma & = \mathbf{SRS} \\
\mathbf S & = \begin{bmatrix} 0.22 & 0 \\ 0 & 0.22 \end{bmatrix} \\
\mathbf R & = \begin{bmatrix} 1 & -.9 \\ -.9 & 1 \end{bmatrix},
\end{align*}

```{r}
# mean vector
mu <- c(0, 0)

# variance/covariance matrix
sd_a1 <- 0.22
sd_a2 <- 0.22
rho   <- -.9

Sigma <- matrix(data = c(sd_a1^2,
                         rho * sd_a1 * sd_a2,
                         rho * sd_a1 * sd_a2,
                         sd_a2^2),
                nrow = 2)

# sample from the distribution with the `mvtnorm::rmvnorm()` function
set.seed(9)

my_samples <- mvtnorm::rmvnorm(n = 1e3, mean = mu, sigma = Sigma)
```

```{r}
# just for demo - not actually used
data.frame(a = my_samples) %>% 
  as_tibble() %>% 
  set_names(str_c("a", 1:2)) %>% 
  summarise(rho = cor(a1, a2))
```

```{r}
# define the function
x_y_grid <- function(x_start = -1.6,
                     x_stop = 1.6,
                     x_length = 101,
                     y_start = -1.6,
                     y_stop = 1.6,
                     y_length = 101) {
  
  x_domain <- seq(from = x_start, to = x_stop, length.out = x_length)
  y_domain <- seq(from = y_start, to = y_stop, length.out = y_length)
  
  x_y_grid_tibble <- tidyr::expand_grid(a1 = x_domain, a2 = y_domain)
  
  return(x_y_grid_tibble)
  
}


# simulate
contour_plot_dat <- x_y_grid() %>% 
  mutate(d = mvtnorm::dmvnorm(as.matrix(.),
                              mean = mu, sigma = Sigma))
```

```{r}
p0 <- contour_plot_dat %>% 
  ggplot() + 
  geom_contour(aes(x = a1, y = a2, z = d), 
               size = 1/8, color = clr_dark,
               breaks = 9^(-(10 * 1:25))) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0))  +
  scale_shape_manual(values = c(21, 19)) +
  scale_color_manual(values = c(`FALSE` = clr0, `TRUE` = clr2)) +
  theme(panel.border = element_rect(color = clr_dark, fill = "transparent"))

metropolis <- function(num_proposals = 50,
                       step_size = 0.1,
                       starting_point = c(-1, 1),
                       seed = 42) {
  set.seed(seed)
  # Initialize vectors where we will keep track of relevant
  candidate_x_history <- rep(-Inf, num_proposals)
  candidate_y_history <- rep(-Inf, num_proposals)
  did_move_history <- rep(FALSE, num_proposals)
  
  # Prepare to begin the algorithm...
  current_point <- starting_point
  
  for(i in 1:num_proposals) {
    
    # "Proposals are generated by adding random Gaussian noise
    # to each parameter"
    
    noise <- rnorm(n = 2, mean = 0, sd = step_size)
    candidate_point <- current_point + noise
    
    # store coordinates of the proposal point
    candidate_x_history[i] <- candidate_point[1]
    candidate_y_history[i] <- candidate_point[2]
    
    # evaluate the density of our posterior at the proposal point
    candidate_prob <- mvtnorm::dmvnorm(candidate_point, mean = mu, sigma = Sigma)
    
    # evaluate the density of our posterior at the current point
    current_prob <- mvtnorm::dmvnorm(current_point, mean = mu, sigma = Sigma)
    
    # Decide whether or not we should move to the candidate point
    acceptance_ratio <- candidate_prob / current_prob
    should_move <- ifelse(runif(n = 1) < acceptance_ratio, TRUE, FALSE)
    
    # Keep track of the decision
    did_move_history[i] <- should_move
    
    # Move if necessary
    if(should_move) {
      current_point <- candidate_point
    }
  }
  
  # once the loop is complete, store the relevant results in a tibble
  results <- tibble::tibble(
    candidate_x = candidate_x_history,
    candidate_y = candidate_y_history,
    accept = did_move_history
  )
  
  # compute the "acceptance rate" by dividing the total number of "moves"
  # by the total number of proposals
  
  number_of_moves <- results %>% dplyr::pull(accept) %>% sum(.)
  acceptance_rate <- number_of_moves/num_proposals
  
  return(list(results = results, acceptance_rate = acceptance_rate))
  
}


round_1 <- metropolis(num_proposals = 50,
                      step_size = 0.1,
                      starting_point = c(-1,1))


round_2 <- metropolis(num_proposals = 50,
                      step_size = 0.25,
                      starting_point = c(-1,1))

p1 <- p0 + 
  geom_point(data = round_1$results,
             mapping = aes(x = candidate_x, y = candidate_y, 
                           color = accept, fill = after_scale(clr_alpha(color,.2))), shape = 21) +
  labs(subtitle = str_c("step size 0.1,\naccept rate ",
                        round_1$acceptance_rate), x = "a1")

p2 <- p0 + 
  geom_point(data = round_2$results,
             mapping = aes(x = candidate_x, y = candidate_y, 
                           color = accept, fill = after_scale(clr_alpha(color,.2))), shape = 21) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(0, 0)) +
  labs(subtitle = str_c("step size 0.25,\naccept rate ",
                        round_2$acceptance_rate), x = "a1")

p1 + p2 + plot_layout(guides = "collect")
```

```{r}
concentration_sim <- function(dimensions = 1, t = 1e3, seed = 42) {
  
  set.seed(seed)
  
  y <- rethinking::rmvnorm(t, rep(0, dimensions), diag(dimensions))
  rad_dist <- function(y) sqrt(sum(y^2))
  rd <- sapply(1:t, function(i) rad_dist( y[i, ])) 
}

data_concentration <- tibble(dimensions = c(1, 10, 100, 1000)) %>% 
  mutate(con = map(dimensions, concentration_sim)) %>% 
  unnest(con) %>% 
  mutate(`# dimensions` = factor(dimensions)) 

data_concentration  %>% 
  ggplot(aes(x = con, fill = `# dimensions`)) +
  geom_density(size = .4, adjust = .6,
               aes(color = after_scale(clr_alpha(fill, 1)))) +
  scale_fill_manual(values = scales::colour_ramp(colors = c(clr0d, clr2) %>% clr_alpha())((0:3)/3)) +
  xlab("Radial distance from mode") +
  theme(legend.position = "bottom")
```

##  Hamiltonian Monte Carlo

```{r}
U <- function( q, a = 0, b = 1, k = 0, d = 1){
  muy <- q[1]
  mux <- q[2]
  U <- sum( dnorm(y , muy, 1, log = TRUE)) + sum( dnorm(x , mux, 1, log = TRUE)) +
   dnorm(muy, a, b, log = TRUE) + dnorm(mux, k, d, log = TRUE)
  return(-U)
}

U_gradient <- function(
  q , a = 0, b = 1, k = 0, d = 1){
  muy <- q[1]
  mux <- q[2]
  G1 <- sum( y - muy ) + (a - muy) / b ^ 2 # dU/dmuy
  G2 <- sum( x - mux ) + (a - mux) / b ^ 2 # dU/dmux
  return(c(-G1, -G2))                      # negative because energy is neg-log-prob
}

U1d <- function( q, a = 0, b = 1, k = 0, d = 1){
  muy <- q[1]
  U <- sum( dnorm(y , muy, 1, log = TRUE)) +
   dnorm(muy, a, b, log = TRUE)
  return(-U)
}

U1d_gradient <- function(
  q , a = 0, b = 1, k = 0, d = 1){
  muy <- q[1]
  G1 <- sum( y - muy ) + (a - muy) / b ^ 2 # dU/dmuy
  return(-G1)                      # negative because energy is neg-log-prob
}
```

```{r}
library(shape)
library(rethinking)
library(ggforce)
library(ggnewscale)

import_trajs <- function(Q, idx,names = c("x", "y")){
  traj <- Q$traj %>% 
    as_tibble() %>% 
    set_names(nm = names) %>% 
    mutate(leapfrog_step = row_number())
  
  ptraj <- Q$ptraj %>% 
    as_tibble() %>% 
    set_names(nm = str_c(names, "_p"))
  
  tibble(sample = idx, traj = list(bind_cols(traj, ptraj)))
}


contour_plot_dat_gaus <- x_y_grid(x_start = -.35,x_stop = .35,
                                  y_start = -.35, y_stop = .35) %>% 
  mutate(d = mvtnorm::dmvnorm(as.matrix(.),
                              mean = c(0,0),
                              sigma = matrix(c(1,0,0,1),nrow = 2)))

y <- rnorm(50)
y <- as.numeric(scale(y))
```


```{r}
set.seed(42)
  S <- list()
  Q <- list()
  Q$q <- .15
  pr <- .3
  step <- .03
  n_samples <- 20
  L <- 11
  
  for(i in 1:n_samples){
    Q <- HMC2(U = U1d, grad_U = U1d_gradient, epsilon = step, L = L, current_q = Q$q)
    for(j in 1:L){
      K0 <- sum(Q$ptraj[j,] ^ 2)/2 # kinetic energy
    }
    S[[i]] <- Q
  }

sample_tib <- map2_dfr(S, seq_along(S), import_trajs, names = c("y")) %>% 
    unnest(traj) %>% 
    mutate(k = (y_p ^ 2 ) /2 ,
           t = 1 + cumsum(leapfrog_step != 1))

sample_tib %>% 
  ggplot(aes(t, y)) +
  geom_hline(yintercept = rep(c(-1,1), each = 5) * rep(c(.5,.48,.41, .33, .2),2),
             color = clr0) +
  geom_link2(aes(group = sample, size = k),
             color = clr_dag) +
  scale_size_continuous(range = c(.15,3.5), guide = "none")+
  new_scale(new_aes = "size")+
  geom_point(data = . %>% filter(leapfrog_step == (L + 1)),
             size = 2.5,
             color = clr2,
             fill = clr_lighten(clr2),
             shape = 21) +
  geom_point(data = sample_tib %>% filter(row_number() %in% c(1, nrow(sample_tib))),
             color = clr2,
             shape = 1,
             size = 4.5) +
  scale_y_continuous(limits = c(-.55,.55),breaks = c(-.46,.46),
                     labels = c("South", "North"))  +
  scale_size_manual(values = c(`TRUE` = 2.5, `FALSE` = .5)) +
  scale_color_manual(values = c(`TRUE` = clr2, `FALSE` = clr0dd)) +
  coord_cartesian(ylim = c(-.5, .5), 
                  xlim = c(-1, 3 + n_samples*L), expand = 0) +
  labs(x = "time", y = "position")+
  theme(panel.border = element_rect(color = clr_dark, fill = "transparent"),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.y = element_text(angle = 90, hjust = .5))
```

```{r}
monty_plot <- function(L = 11,
                       n_samples = 4,
                       contour_plot_dat,
                       contour_breaks,
                       seed = 42,
                       start_point = c(-.1,.2)){
  set.seed(seed)
  S <- list()
  Q <- list()
  Q$q <- start_point
  pr <- .3
  step <- .03
  
  for(i in 1:n_samples){
    Q <- HMC2(U = U, grad_U = U_gradient, epsilon = step, L = L, current_q = Q$q)
    for(j in 1:L){
      K0 <- sum(Q$ptraj[j,] ^ 2)/2 # kinetic energy
    }
    S[[i]] <- Q
  }
  
  sample_tib <- map2_dfr(S, seq_along(S), import_trajs) %>% 
    unnest(traj) %>% 
    mutate(k = (x_p ^ 2 + y_p ^ 2 ) /2 )
  
  sample_tib %>% 
    ggplot(aes(x, y)) +
    geom_contour(data = contour_plot_dat,
                 aes(x = a1, y = a2, z = d), 
                 size = .2,
                 breaks = contour_breaks,
                 color = clr_dark) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0))  +
    geom_link2(aes(group = sample, size = k),
               color = clr_dag) +
    scale_size_continuous(range = c(.15,3.5), guide = "none")+
    new_scale(new_aes = "size")+
    geom_point(data = . %>% filter(leapfrog_step > 1),
               aes(size = leapfrog_step == (L + 1),
                   color = leapfrog_step == (L + 1),
                   fill = after_scale(clr_lighten(color,.3))),
               shape = 21) +
    geom_point(data = sample_tib %>% filter(row_number() %in% c(1, nrow(sample_tib))),
               color = clr2,
               shape = 1,
               size = 4.5) +
    scale_size_manual(values = c(`TRUE` = 2.5, `FALSE` = .5)) +
    scale_color_manual(values = c(`TRUE` = clr2, `FALSE` = clr0dd)) +
    theme(panel.border = element_rect(color = clr_dark, fill = "transparent"))
}
```


```{r, fig.asp = .55}
x <- rnorm(50)
x <- as.numeric(scale(x))

monty_plot(contour_plot_dat = contour_plot_dat_gaus,
           contour_breaks = .001* seq(146,160, by = 2.5),
           seed = 23) +
monty_plot(L = 28,
           contour_plot_dat = contour_plot_dat_gaus,
           contour_breaks = .001* seq(146,160, by = 2.5),
           seed = 23) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank()) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")
```

## Easy HMC: `rethinking::ulam()`

Revisiting the ruggedness model:

$$
\begin{array}{rclr}
log(y_{i}) & \sim & Normal( \mu_{i}, \sigma) & \textrm{[likelihood]}\\
\mu_{i} & = & \alpha_{CID[i]} + \beta_{CID[i]} (r_{i} - \overline{r}) & \textrm{[linear model]}\\
\alpha & \sim & Normal(1, 0.1) & \textrm{[$\alpha$ prior]}\\
\beta & \sim & Normal(0, 0.3) & \textrm{[$\beta$ prior]}\\
\sigma & \sim & Exponential(1)  & \textrm{[$\sigma$ prior]}
\end{array}
$$


```{r}
data(rugged)

data_rugged <- rugged %>% 
  as_tibble() %>% 
  mutate(log_gdp = log(rgdppc_2000)) %>% 
  filter(complete.cases(rgdppc_2000)) %>% 
  mutate(log_gdp_std = log_gdp / mean(log_gdp),
         rugged_std = rugged / max(rugged),
         cont_idx = as.integer(2 - cont_africa))
```

The old way using `quap()`

```{r}
model_rugged_slope <- quap(
   flist = alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- alpha[cont_idx] + beta[cont_idx] * ( rugged_std - 0.215 ),
    alpha[cont_idx] ~ dnorm(1, 0.1),
    beta[cont_idx] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = data_rugged
)

precis(model_rugged_slope, depth = 2) %>% 
  knit_precis()
```

Using `Stan` / `ulam()`:

```{r, results = "hide"}
data_rugged_list <- data_rugged %>% 
  dplyr::select(log_gdp_std:cont_idx) %>% 
  as.list()

model_rugged_slope_stan <- ulam(
   flist = alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- alpha[cont_idx] + beta[cont_idx] * ( rugged_std - 0.215 ),
    alpha[cont_idx] ~ dnorm(1, 0.1),
    beta[cont_idx] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ),
  data = data_rugged_list,
  chains = 4,
  cores = 4
)
```

Looking at the translated Stan code

```{r}
stancode(model_rugged_slope_stan)
```

The model summaries

```{r}
show(model_rugged_slope_stan)

precis(model_rugged_slope_stan, depth = 2) %>% 
  knit_precis()
```

```{r, fig.asp = .8}
my_lower <- function(data, mapping, ...) {
  ggplot(data = data, mapping = mapping) + 
    geom_bin2d() +
    scale_fill_gradient(low = clr0, 
                        high = clr2) +
    theme(panel.grid = element_blank())
}

my_upper <- function(...){
          ggally_cor(...,display_grid = FALSE) + theme_void()
          }


extract.samples(model_rugged_slope_stan) %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  ggpairs(
     lower = list(continuous = wrap(my_lower)),
        diag = list(continuous = wrap("densityDiag", fill = fll0,
                                      color = clr0d, adjust = .7)),
        upper = list(continuous = wrap(my_upper ,
          size = 5, color = "black", family = "Josefin sans")) ) +
    theme(panel.border = element_rect(color = clr_dark, fill = "transparent"))
```

The density for $\sigma$ is skewed, which is expected.

### Checking the Chain

**Trace plot**

```{r}
library(ggmcmc)

rugged_pars <- c("alpha[1]", "alpha[2]", "beta[1]", "beta[2]")
clr_chains <- function(n = 4, alpha = .7){scales::colour_ramp(colors = c(clr0dd, clr2))(seq(0,1,length.out = n))%>% clr_lighten(.2) %>% clr_alpha(alpha = alpha)}

ggs(model_rugged_slope_stan@stanfit, inc_warmup = TRUE) %>%
  mutate(chain = factor(Chain)) %>% 
  filter(Parameter != "sigma") %>% 
  ggplot(aes(x = Iteration, y = value)) +
  annotate(geom = "rect", 
           xmin = 0, xmax = 500, ymin = -Inf, ymax = Inf,
           fill = clr0d, alpha = .3, size = 0) +
  geom_line(aes(color = chain),
            size = .15) +
  scale_color_manual(values = clr_chains() ) +
  facet_wrap(~ Parameter, scales = "free_y") +
    labs(title = "custom trace plots with warmups via ggmcmc::ggs()",
       x = NULL, y = NULL) +
  theme(legend.position = "bottom") 
```

**Trace Rank plot**

```{r}
library(bayesplot)
model_rugged_slope_stan@stanfit %>% 
  mcmc_rank_overlay(pars = vars(`alpha[1]`:`beta[2]`), n_bins = 60) +
  scale_color_manual(values = clr_chains() ) +
  ggtitle("custom trank plots") +
  # coord_cartesian(ylim = c(0, NA)) +
  theme(legend.position = "bottom")
```

## Care and feeding of your Markov Chain

```{r, results = "hide"}
set.seed(11)
model_flat <- ulam(
  flist = alist(
    y ~ dnorm( mu, sigma ),
    mu <- alpha,
    alpha ~ dnorm( 0, 1000 ),
    sigma ~ dexp( 0.0001 )
  ),
  data = list(y = c(-1, 1)),
  chains = 3
)
```


```{r}
precis(model_flat) %>% 
  knit_precis()
```

```{r}
p1 <- ggs(model_flat@stanfit, inc_warmup = TRUE) %>%
  mutate(chain = factor(Chain)) %>% 
  ggplot(aes(x = Iteration, y = value)) +
  annotate(geom = "rect", 
           xmin = 0, xmax = 500, ymin = -Inf, ymax = Inf,
           fill = clr0d, alpha = .3, size = 0) +
  geom_line(aes(color = chain),
            size = .25) +
  scale_color_manual(values = clr_chains(alpha = 1), guide ="none") +
  facet_wrap(~ Parameter, scales = "free_y") +
    labs(x = NULL, y = NULL)

p2 <- model_flat@stanfit %>% 
  mcmc_rank_overlay(pars = vars(`alpha`:`sigma`), n_bins = 60) +
  scale_color_manual(values = clr_chains(), guide ="none")

p1 / p2
```


---

```{r env_export}
library(rlang)
chapter9_models <- env(
)

write_rds(chapter9_models, "envs/chapter9_models.rds")
```


## Homework

**E1**

```{r E1}

```

**E2**

```{r E2}

```

**E3**

```{r E3}

```

**E4**

```{r E4}

```

**M1**

```{r M1}

```

**M2**

```{r M2}

```

**M3**

```{r M3}

```

**M4**

```{r M4}

```

**M5**

```{r M5}

```

**M6**

```{r M6}

```

**H1**

```{r H1}

```

**H2**

```{r H2}

```

**H3**

```{r H3}

```

**H4**

```{r H4}

```

**H5**

```{r H5}

```

## {brms} section

## pymc3 section

---

<div id="myModal" class="modal">
  <span class="close">&times;</span>
  <img class="modal-content" id="img01">
  <div id="caption"></div>
</div>

<script src="./js/zoom.js"></script>